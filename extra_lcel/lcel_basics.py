import os
import time
from dotenv import load_dotenv

# å¯¼å…¥ LangChain æ ¸å¿ƒç»„ä»¶
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
# å¯¼å…¥ LCEL ç¥å™¨
from langchain_core.runnables import RunnablePassthrough, RunnableParallel, chain

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_model():
    """åˆå§‹åŒ–æ¨¡å‹"""
    return init_chat_model(
        os.getenv("MODEL_NAME"),
        temperature=0.7,
        api_key=os.getenv("API_KEY"),
        model_provider=os.getenv("MODEL_PROVIDER", "ollama"),
        base_url=os.getenv("BASE_URL"),
    )

def test_magic_1_linear():
    """é­”æ³•ä¸€ï¼šåŸºç¡€çº¿æ€§é“¾ (Linear Chain)"""
    print("\n--- ğŸª„ é­”æ³•ä¸€ï¼šåŸºç¡€çº¿æ€§é“¾ ---")
    
    model = get_model()
    prompt = ChatPromptTemplate.from_template("è¯·ä¸ºä¸€å®¶ç”Ÿäº§ {product} çš„å…¬å¸èµ·ä¸€ä¸ªå¥½å¬çš„ä¸­æ–‡åå­—ã€‚åªè¿”å›åå­—ï¼Œä¸è¦å…¶ä»–åºŸè¯ã€‚")
    parser = StrOutputParser()

    # ğŸ”— ç»„è£…ï¼šPrompt -> Model -> Parser
    # è¿™å°±æ˜¯æœ€ç»å…¸çš„ LCEL èŒƒå¼
    chain = prompt | model | parser

    # è°ƒç”¨
    result = chain.invoke({"product": "é«˜æ€§èƒ½æ˜¾å¡"})
    print(f"äº§å“: é«˜æ€§èƒ½æ˜¾å¡ -> å…¬å¸å: {result}")
    
    # âœ¨ éšè—æŠ€å·§ï¼šæ‰“å°é“¾æ¡ç»“æ„
    print("\n[Debug] é“¾æ¡ç»“æ„å›¾:")
    chain.get_graph().print_ascii()
    
    return chain

def test_magic_2_custom_func():
    """é­”æ³•äºŒï¼šæ’å…¥è‡ªå®šä¹‰å‡½æ•° (@chain)"""
    print("\n--- ğŸª„ é­”æ³•äºŒï¼šæ’å…¥è‡ªå®šä¹‰å‡½æ•° ---")
    
    model = get_model()
    prompt = ChatPromptTemplate.from_template("ç¿»è¯‘æˆè‹±æ–‡: {text}")
    
    # å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„ Runnable å‡½æ•°
    # @chain è£…é¥°å™¨ä¼šè‡ªåŠ¨è¿”å›ä¸€ä¸ª Runnable å¯¹è±¡ã€‚ç­‰åŒäº RunnableLambda(add_prefix) 
    @chain
    def add_prefix(text):
        return f"âœ¨ ç»“æœ: {text.strip()} âœ¨"

    # ç»„è£…ï¼šPrompt -> Model -> StrOutputParser -> è‡ªå®šä¹‰å‡½æ•°
    pipeline = prompt | model | StrOutputParser() | add_prefix
    
    result = pipeline.invoke({"text": "ä½ å¥½ï¼ŒLangChain"})
    print(result)

def test_magic_3_passthrough():
    """é­”æ³•ä¸‰ï¼šé€ä¼  (Passthrough) â€”â€” è§£å†³ä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜"""
    print("\n--- ğŸª„ é­”æ³•ä¸‰ï¼šé€ä¼  (Passthrough) ---")
    
    model = get_model()
    parser = StrOutputParser()
    
    # æ­¥éª¤1ï¼šç”Ÿæˆåå­—
    name_prompt = ChatPromptTemplate.from_template("è¯·ä¸ºä¸€å®¶ç”Ÿäº§ {product} çš„å…¬å¸èµ·ä¸€ä¸ªå¥½å¬çš„ä¸­æ–‡åå­—ã€‚åªè¿”å›åå­—ã€‚")
    generate_name_chain = name_prompt | model | parser

    # æ­¥éª¤2ï¼šå†™ Slogan
    # æ³¨æ„ï¼šè¿™ä¸ª Prompt éœ€è¦ {company_name} (ä¸Šä¸€æ­¥ç”Ÿæˆçš„) å’Œ {product} (æœ€å¼€å§‹è¾“å…¥çš„)
    slogan_prompt = ChatPromptTemplate.from_template(
        "å…¬å¸åæ˜¯ï¼š{company_name}ï¼Œäº§å“æ˜¯ï¼š{product}ã€‚è¯·å†™ä¸€å¥æœ—æœ—ä¸Šå£çš„ Sloganï¼ˆå£å·ï¼‰ã€‚"
    )

    # ğŸ”— ç»„è£…å¤æ‚é“¾
    # ä½¿ç”¨å­—å…¸ç»“æ„ï¼ŒRunnablePassthrough() ä»£è¡¨"åŸå§‹è¾“å…¥"
    full_chain = (
        {"product": RunnablePassthrough(), "company_name": generate_name_chain} 
        | slogan_prompt 
        | model 
        | parser
    )

    result = full_chain.invoke("é‡å­è®¡ç®—æœº")
    print(f"ç»“æœ: {result}")

def test_magic_4_parallel():
    """é­”æ³•å››ï¼šå¹¶è¡Œå¤„ç† (Parallel) â€”â€” æ•ˆç‡å€å¢"""
    print("\n--- ğŸª„ é­”æ³•å››ï¼šå¹¶è¡Œå¤„ç† (Parallel) ---")
    
    model = get_model()
    parser = StrOutputParser()

    # å®šä¹‰ä¸¤ä¸ªå¹¶è¡Œçš„é“¾
    pros_chain = ChatPromptTemplate.from_template("ç®€çŸ­åˆ—å‡º {product} çš„ä¸€ä¸ªæ ¸å¿ƒä¼˜ç‚¹") | model | parser
    cons_chain = ChatPromptTemplate.from_template("ç®€çŸ­åˆ—å‡º {product} çš„ä¸€ä¸ªæ ¸å¿ƒç¼ºç‚¹") | model | parser

    # ğŸ”— ç»„è£…å¹¶è¡Œé“¾
    # å°±åƒç”µè·¯å¹¶è”ä¸€æ ·ï¼Œä¸¤è·¯åŒæ—¶è·‘
    map_chain = RunnableParallel(
        pros=pros_chain,
        cons=cons_chain
    )

    start_time = time.time()
    print("â³ å¼€å§‹å¹¶è¡Œæ€è€ƒ...")
    
    # è°ƒç”¨
    result = map_chain.invoke({"product": "çº¯ç”µåŠ¨æ±½è½¦"})
    
    end_time = time.time()
    print(f"âœ… å®Œæˆ! è€—æ—¶: {end_time - start_time:.2f}ç§’")
    print(f"ä¼˜ç‚¹: {result['pros']}")
    print(f"ç¼ºç‚¹: {result['cons']}")


def test_stream():
    """é­”æ³•äº”ï¼šæµå¼è¾“å‡º (Streaming)"""
    print("\n--- ğŸª„ é­”æ³•äº”ï¼šæµå¼è¾“å‡º (Streaming) ---")
    
    model = get_model()
    prompt = ChatPromptTemplate.from_template("å…¬å¸åæ˜¯ï¼š{company_name}ï¼Œäº§å“æ˜¯ï¼š{product}ã€‚è¯·å†™ä¸€å¥æœ—æœ—ä¸Šå£çš„ Sloganï¼ˆå£å·ï¼‰ã€‚")
    parser = StrOutputParser()

    # ğŸ”— ç»„è£…ï¼šPrompt -> Model -> Parser
    # è¿™å°±æ˜¯æœ€ç»å…¸çš„ LCEL èŒƒå¼
    chain = prompt | model | parser

    # è°ƒç”¨
    for chunk in chain.stream({"company_name": "èŠ¯æ“", "product": "é«˜æ€§èƒ½æ˜¾å¡"}):
        if chunk:
            # chunk æ˜¯å®æ—¶åå‡ºçš„å­—ç¬¦
            print(chunk, end="|", flush=True)
    
    return chain


if __name__ == "__main__":
    # æŒ‰éœ€è¿è¡Œæµ‹è¯•
    # test_magic_1_linear()
    # test_magic_2_custom_func()
    # test_magic_3_passthrough()
    # test_magic_4_parallel()
    test_stream()